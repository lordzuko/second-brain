<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content=" Week 1 Classification Part 1 Introduction to the biological neuron that served as inspiration for the Perceptron Linear classification and simple linear discriminant functions, and the concept of hyperplanes Multicategory classification, linear machines and generalized linear discriminants Normalisation, solution regions, the margin Week 2 Classification Part 2 Convex function, set and hull The Perceptron Criterion and Algorithm The MSE Classification Procedure Support Vector Machines Week 3 Neural Network Multilayer Neural Networks: forward operation and expressive power Multilayer Neural Networks: Back-propagation setup Multilayer Neural Networks: Back-propagation algorithm Multilayer Neural Networks: Training protocols Week 4 CNN Convolutional Neural Networks and Deep Learning Optimization Reviewing Background for Optimisation Bracketing Methods for 1-d Optimisation Gradient Descent Newton’s Method Week 5 Optimization Levenberg Marquardt Gradient descent with line minima Conjugate Gradient Descent Week 6 Bayes Decision Theory Supervised vs unsupervised learning; probabilistic view to learning Bayes formula, Bayes decision rule and probability of error Examples of statistical classification from a Bayesian view Week 7 Model Learning Maximum likelihood estimation; non-linear regression; Maximum likelihood fitting of Gaussians Overfitting; bias-variance dilemma Learning models with Bayesian; fitting 1D Gaussians; the Bayes – Maximum likelihood link Week 8 Clustering K-means clustering; k-means for vector quantization; optimality of k-means Relation to matrix factorisation; k-medoids algorithm Mixture of Gaussians and EM algorithm Week 9 HMM First-order Markov models; first-order hidden Markov models; different models Three fundamental problems; evaluation problem; isolated word speech recognition Evaluation problem; decoding problem; learning problem Week 10 Principal Component Analysis (PCA) Principal component analysis; importance and implications; subspace projections Relation to matrix factorisation; PCA example Independent Component Analysis (ICA) Independent component analysis; differences with PCA "><title>Himanshu Maurya</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://lordzuko.github.io//icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&family=Source+Sans+Pro:wght@400;600;700&family=Fira+Code:wght@400;700&family=Oswald:wght@700&display=block" rel=stylesheet><link href=https://lordzuko.github.io/styles.56d47f5cc6b40c4c97475ab7dab36b03.min.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script src=https://lordzuko.github.io/js/popover.688c5dcb89a57776d7f1cbeaf6f7c44b.min.js></script>
<script>const BASE_URL="https://lordzuko.github.io/",fetchData=Promise.all([fetch("https://lordzuko.github.io/indices/linkIndex.71139b94f3f29dfda52032fbfdd80a2a.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://lordzuko.github.io/indices/contentIndex.fab86bbe49cf4e5f56dd16934c1866ee.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),draw=()=>{const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(draw);e.textContent="",drawGraph("https://lordzuko.github.io",[{"/moc":"#4388cc"}],1,!0,!1,!0),initPopover("https://lordzuko.github.io",!0,!0),renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})}</script><script>window.Million={navigate:e=>window.location.href=e,prefetch:()=>{}},draw()</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://lordzuko.github.io/js/search.1d58f2d3eaac68cc50beeb118d91edc9.min.js></script><div class=bodyContent><div class="singlePage logo-background"><header><a class=header_logo href=https://lordzuko.github.io/><img src=../../../header.svg alt="Himanshu Maurya"></a><div class=spacer></div><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></header><article><ul class=tags></ul><ul><li><input checked disabled type=checkbox> Week 1<ul><li><input checked disabled type=checkbox> Classification Part 1<ul><li>Introduction to the biological neuron that served as inspiration for the Perceptron</li><li>Linear classification and simple linear discriminant functions, and the concept of hyperplanes</li><li>Multicategory classification, linear machines and generalized linear discriminants</li><li>Normalisation, solution regions, the margin</li></ul></li></ul></li><li><input checked disabled type=checkbox> Week 2<ul><li><input checked disabled type=checkbox> Classification Part 2<ul><li>Convex function, set and hull</li><li>The Perceptron Criterion and Algorithm</li><li>The MSE Classification Procedure</li><li>Support Vector Machines</li></ul></li></ul></li><li><input checked disabled type=checkbox> Week 3<ul><li><input checked disabled type=checkbox> Neural Network<ul><li>Multilayer Neural Networks: forward operation and expressive power</li><li>Multilayer Neural Networks: Back-propagation setup</li><li>Multilayer Neural Networks: Back-propagation algorithm</li><li>Multilayer Neural Networks: Training protocols</li></ul></li></ul></li><li><input disabled type=checkbox> Week 4<ul><li><input disabled type=checkbox> CNN<ul><li>Convolutional Neural Networks and Deep Learning</li></ul></li><li><input disabled type=checkbox> Optimization<ul><li>Reviewing Background for Optimisation</li><li>Bracketing Methods for 1-d Optimisation</li><li>Gradient Descent</li><li>Newton’s Method</li></ul></li></ul></li><li><input disabled type=checkbox> Week 5<ul><li><input disabled type=checkbox> Optimization<ul><li>Levenberg Marquardt</li><li>Gradient descent with line minima</li><li>Conjugate Gradient Descent</li></ul></li></ul></li><li><input disabled type=checkbox> Week 6<ul><li><input disabled type=checkbox> Bayes Decision Theory<ul><li>Supervised vs unsupervised learning; probabilistic view to learning</li><li>Bayes formula, Bayes decision rule and probability of error</li><li>Examples of statistical classification from a Bayesian view</li></ul></li></ul></li><li><input disabled type=checkbox> Week 7<ul><li><input disabled type=checkbox> Model Learning<ul><li>Maximum likelihood estimation; non-linear regression; Maximum likelihood fitting of Gaussians</li><li>Overfitting; bias-variance dilemma</li><li>Learning models with Bayesian; fitting 1D Gaussians; the Bayes – Maximum likelihood link</li></ul></li></ul></li><li><input disabled type=checkbox> Week 8<ul><li><input disabled type=checkbox> Clustering<ul><li>K-means clustering; k-means for vector quantization; optimality of k-means</li><li>Relation to matrix factorisation; k-medoids algorithm</li><li>Mixture of Gaussians and EM algorithm</li></ul></li></ul></li><li><input disabled type=checkbox> Week 9<ul><li><input disabled type=checkbox> HMM<ul><li>First-order Markov models; first-order hidden Markov models; different models</li><li>Three fundamental problems; evaluation problem; isolated word speech recognition</li><li>Evaluation problem; decoding problem; learning problem</li></ul></li></ul></li><li><input disabled type=checkbox> Week 10<ul><li><input disabled type=checkbox> Principal Component Analysis (PCA)<ul><li>Principal component analysis; importance and implications; subspace projections</li><li>Relation to matrix factorisation; PCA example</li></ul></li><li><input disabled type=checkbox> Independent Component Analysis (ICA)<ul><li>Independent component analysis; differences with PCA</li></ul></li></ul></li></ul></article></div><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://lordzuko.github.io/js/graph.5388a070919094961d3e5151252e9065.js></script></div></div><div class=footer><div class=outreach><h3>Have a question?</h3><p>Reach out via <strong><a href=mailto:himanshumaurya2214225@gmail.com target=_blank>Email</a></strong> or
<strong><a href=https://twitter.com/lordzuko2 target=_blank>Twitter</a></strong>.</p><p>If you liked the post, <a href="https://twitter.com/intent/tweet?url=https%3a%2f%2flordzuko.github.io%2fUoE%2fMLSP%2fTrack-Weeks%2f&text=&via=lordzuko2" target=_blank>click here to share it with your friends on Twitter</a>.<br>I ♥️ hearing when the post was
helpful. It makes me smile 😄.</p></div><div id=contact_buttons><footer><p>Made with ♥ in Richmond, VA<br>© 2023 Himanshu Maurya</p><ul><li><a href=https://twitter.com/lordzuko2 target=_blank>Twitter</a></li><li><a href=https://www.youtube.com/@HimanshuMauryalordzuko target=_blank>YouTube</a></li><li><a href=https://github.com/lordzuko target=_blank>Github</a></li></ul></footer></div></div></div></body></html>